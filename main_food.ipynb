{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2950ed91-2fb4-4d15-9be2-1756831907f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "from shutil import copy\n",
    "from shutil import copytree, rmtree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aff09a9-772b-43ed-bc10-d20b0cd07285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loading function\n",
    "def get_data_extract():\n",
    "    if \"food_data\" in os.listdir():\n",
    "        print(\"Dataset already exists\")\n",
    "    else:\n",
    "        tf.keras.utils.get_file(\n",
    "        './food-101.tar.gz',\n",
    "        'http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz',\n",
    "        cache_subdir='/content',\n",
    "        extract=True,\n",
    "        archive_format='tar',\n",
    "        cache_dir=None)\n",
    "        print(\"Dataset downloaded and extracted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb5c413-fe83-43bf-a59d-db53b9d8aaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists\n"
     ]
    }
   ],
   "source": [
    "#getting data\n",
    "get_data_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88082113-942f-48a2-8f6a-d5eae0d01099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test data extraction function\n",
    "def prepare_data(filepath, src, dest):\n",
    "    classes_images = defaultdict(list)\n",
    "    with open(filepath, 'r') as txt:\n",
    "        paths = [read.strip() for read in txt.readlines()]\n",
    "        for p in paths:\n",
    "            food = p.split('/')\n",
    "            classes_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "    for food in classes_images.keys():\n",
    "        print(\"\\nCopying images into \",food)\n",
    "        if not os.path.exists(os.path.join(dest,food)):\n",
    "            os.makedirs(os.path.join(dest,food))\n",
    "        for i in classes_images[food]:\n",
    "            copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
    "    print(\"Copying Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c72d118-3e18-47e9-9a84-39387f55e5d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying images into  apple_pie\n",
      "\n",
      "Copying images into  baby_back_ribs\n",
      "\n",
      "Copying images into  baklava\n",
      "\n",
      "Copying images into  beef_carpaccio\n",
      "\n",
      "Copying images into  beef_tartare\n",
      "\n",
      "Copying images into  beet_salad\n",
      "\n",
      "Copying images into  beignets\n",
      "\n",
      "Copying images into  bibimbap\n",
      "\n",
      "Copying images into  bread_pudding\n",
      "\n",
      "Copying images into  breakfast_burrito\n",
      "\n",
      "Copying images into  bruschetta\n",
      "\n",
      "Copying images into  caesar_salad\n",
      "\n",
      "Copying images into  cannoli\n",
      "\n",
      "Copying images into  caprese_salad\n",
      "\n",
      "Copying images into  carrot_cake\n",
      "\n",
      "Copying images into  ceviche\n",
      "\n",
      "Copying images into  cheesecake\n",
      "\n",
      "Copying images into  cheese_plate\n",
      "\n",
      "Copying images into  chicken_curry\n",
      "\n",
      "Copying images into  chicken_quesadilla\n",
      "\n",
      "Copying images into  chicken_wings\n",
      "\n",
      "Copying images into  chocolate_cake\n",
      "\n",
      "Copying images into  chocolate_mousse\n",
      "\n",
      "Copying images into  churros\n",
      "\n",
      "Copying images into  clam_chowder\n",
      "\n",
      "Copying images into  club_sandwich\n",
      "\n",
      "Copying images into  crab_cakes\n",
      "\n",
      "Copying images into  creme_brulee\n",
      "\n",
      "Copying images into  croque_madame\n",
      "\n",
      "Copying images into  cup_cakes\n",
      "\n",
      "Copying images into  deviled_eggs\n",
      "\n",
      "Copying images into  donuts\n",
      "\n",
      "Copying images into  dumplings\n",
      "\n",
      "Copying images into  edamame\n",
      "\n",
      "Copying images into  eggs_benedict\n",
      "\n",
      "Copying images into  escargots\n",
      "\n",
      "Copying images into  falafel\n",
      "\n",
      "Copying images into  filet_mignon\n",
      "\n",
      "Copying images into  fish_and_chips\n",
      "\n",
      "Copying images into  foie_gras\n",
      "\n",
      "Copying images into  french_fries\n",
      "\n",
      "Copying images into  french_onion_soup\n",
      "\n",
      "Copying images into  french_toast\n",
      "\n",
      "Copying images into  fried_calamari\n",
      "\n",
      "Copying images into  fried_rice\n",
      "\n",
      "Copying images into  frozen_yogurt\n",
      "\n",
      "Copying images into  garlic_bread\n",
      "\n",
      "Copying images into  gnocchi\n",
      "\n",
      "Copying images into  greek_salad\n",
      "\n",
      "Copying images into  grilled_cheese_sandwich\n",
      "\n",
      "Copying images into  grilled_salmon\n",
      "\n",
      "Copying images into  guacamole\n",
      "\n",
      "Copying images into  gyoza\n",
      "\n",
      "Copying images into  hamburger\n",
      "\n",
      "Copying images into  hot_and_sour_soup\n",
      "\n",
      "Copying images into  hot_dog\n",
      "\n",
      "Copying images into  huevos_rancheros\n",
      "\n",
      "Copying images into  hummus\n",
      "\n",
      "Copying images into  ice_cream\n",
      "\n",
      "Copying images into  lasagna\n",
      "\n",
      "Copying images into  lobster_bisque\n",
      "\n",
      "Copying images into  lobster_roll_sandwich\n",
      "\n",
      "Copying images into  macaroni_and_cheese\n",
      "\n",
      "Copying images into  macarons\n",
      "\n",
      "Copying images into  miso_soup\n",
      "\n",
      "Copying images into  mussels\n",
      "\n",
      "Copying images into  nachos\n",
      "\n",
      "Copying images into  omelette\n",
      "\n",
      "Copying images into  onion_rings\n",
      "\n",
      "Copying images into  oysters\n",
      "\n",
      "Copying images into  pad_thai\n",
      "\n",
      "Copying images into  paella\n",
      "\n",
      "Copying images into  pancakes\n",
      "\n",
      "Copying images into  panna_cotta\n",
      "\n",
      "Copying images into  peking_duck\n",
      "\n",
      "Copying images into  pho\n",
      "\n",
      "Copying images into  pizza\n",
      "\n",
      "Copying images into  pork_chop\n",
      "\n",
      "Copying images into  poutine\n",
      "\n",
      "Copying images into  prime_rib\n",
      "\n",
      "Copying images into  pulled_pork_sandwich\n",
      "\n",
      "Copying images into  ramen\n",
      "\n",
      "Copying images into  ravioli\n",
      "\n",
      "Copying images into  red_velvet_cake\n",
      "\n",
      "Copying images into  risotto\n",
      "\n",
      "Copying images into  samosa\n",
      "\n",
      "Copying images into  sashimi\n",
      "\n",
      "Copying images into  scallops\n",
      "\n",
      "Copying images into  seaweed_salad\n",
      "\n",
      "Copying images into  shrimp_and_grits\n",
      "\n",
      "Copying images into  spaghetti_bolognese\n",
      "\n",
      "Copying images into  spaghetti_carbonara\n",
      "\n",
      "Copying images into  spring_rolls\n",
      "\n",
      "Copying images into  steak\n",
      "\n",
      "Copying images into  strawberry_shortcake\n",
      "\n",
      "Copying images into  sushi\n",
      "\n",
      "Copying images into  tacos\n",
      "\n",
      "Copying images into  takoyaki\n",
      "\n",
      "Copying images into  tiramisu\n",
      "\n",
      "Copying images into  tuna_tartare\n",
      "\n",
      "Copying images into  waffles\n",
      "Copying Done!\n"
     ]
    }
   ],
   "source": [
    "#getting train data\n",
    "prepare_data('food_data/food-101/meta/train.txt', 'food_data/food-101/images', 'food_data/food-101/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a504826d-4eca-4702-b8a6-17d67d66cce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying images into  apple_pie\n",
      "\n",
      "Copying images into  baby_back_ribs\n",
      "\n",
      "Copying images into  baklava\n",
      "\n",
      "Copying images into  beef_carpaccio\n",
      "\n",
      "Copying images into  beef_tartare\n",
      "\n",
      "Copying images into  beet_salad\n",
      "\n",
      "Copying images into  beignets\n",
      "\n",
      "Copying images into  bibimbap\n",
      "\n",
      "Copying images into  bread_pudding\n",
      "\n",
      "Copying images into  breakfast_burrito\n",
      "\n",
      "Copying images into  bruschetta\n",
      "\n",
      "Copying images into  caesar_salad\n",
      "\n",
      "Copying images into  cannoli\n",
      "\n",
      "Copying images into  caprese_salad\n",
      "\n",
      "Copying images into  carrot_cake\n",
      "\n",
      "Copying images into  ceviche\n",
      "\n",
      "Copying images into  cheesecake\n",
      "\n",
      "Copying images into  cheese_plate\n",
      "\n",
      "Copying images into  chicken_curry\n",
      "\n",
      "Copying images into  chicken_quesadilla\n",
      "\n",
      "Copying images into  chicken_wings\n",
      "\n",
      "Copying images into  chocolate_cake\n",
      "\n",
      "Copying images into  chocolate_mousse\n",
      "\n",
      "Copying images into  churros\n",
      "\n",
      "Copying images into  clam_chowder\n",
      "\n",
      "Copying images into  club_sandwich\n",
      "\n",
      "Copying images into  crab_cakes\n",
      "\n",
      "Copying images into  creme_brulee\n",
      "\n",
      "Copying images into  croque_madame\n",
      "\n",
      "Copying images into  cup_cakes\n",
      "\n",
      "Copying images into  deviled_eggs\n",
      "\n",
      "Copying images into  donuts\n",
      "\n",
      "Copying images into  dumplings\n",
      "\n",
      "Copying images into  edamame\n",
      "\n",
      "Copying images into  eggs_benedict\n",
      "\n",
      "Copying images into  escargots\n",
      "\n",
      "Copying images into  falafel\n",
      "\n",
      "Copying images into  filet_mignon\n",
      "\n",
      "Copying images into  fish_and_chips\n",
      "\n",
      "Copying images into  foie_gras\n",
      "\n",
      "Copying images into  french_fries\n",
      "\n",
      "Copying images into  french_onion_soup\n",
      "\n",
      "Copying images into  french_toast\n",
      "\n",
      "Copying images into  fried_calamari\n",
      "\n",
      "Copying images into  fried_rice\n",
      "\n",
      "Copying images into  frozen_yogurt\n",
      "\n",
      "Copying images into  garlic_bread\n",
      "\n",
      "Copying images into  gnocchi\n",
      "\n",
      "Copying images into  greek_salad\n",
      "\n",
      "Copying images into  grilled_cheese_sandwich\n",
      "\n",
      "Copying images into  grilled_salmon\n",
      "\n",
      "Copying images into  guacamole\n",
      "\n",
      "Copying images into  gyoza\n",
      "\n",
      "Copying images into  hamburger\n",
      "\n",
      "Copying images into  hot_and_sour_soup\n",
      "\n",
      "Copying images into  hot_dog\n",
      "\n",
      "Copying images into  huevos_rancheros\n",
      "\n",
      "Copying images into  hummus\n",
      "\n",
      "Copying images into  ice_cream\n",
      "\n",
      "Copying images into  lasagna\n",
      "\n",
      "Copying images into  lobster_bisque\n",
      "\n",
      "Copying images into  lobster_roll_sandwich\n",
      "\n",
      "Copying images into  macaroni_and_cheese\n",
      "\n",
      "Copying images into  macarons\n",
      "\n",
      "Copying images into  miso_soup\n",
      "\n",
      "Copying images into  mussels\n",
      "\n",
      "Copying images into  nachos\n",
      "\n",
      "Copying images into  omelette\n",
      "\n",
      "Copying images into  onion_rings\n",
      "\n",
      "Copying images into  oysters\n",
      "\n",
      "Copying images into  pad_thai\n",
      "\n",
      "Copying images into  paella\n",
      "\n",
      "Copying images into  pancakes\n",
      "\n",
      "Copying images into  panna_cotta\n",
      "\n",
      "Copying images into  peking_duck\n",
      "\n",
      "Copying images into  pho\n",
      "\n",
      "Copying images into  pizza\n",
      "\n",
      "Copying images into  pork_chop\n",
      "\n",
      "Copying images into  poutine\n",
      "\n",
      "Copying images into  prime_rib\n",
      "\n",
      "Copying images into  pulled_pork_sandwich\n",
      "\n",
      "Copying images into  ramen\n",
      "\n",
      "Copying images into  ravioli\n",
      "\n",
      "Copying images into  red_velvet_cake\n",
      "\n",
      "Copying images into  risotto\n",
      "\n",
      "Copying images into  samosa\n",
      "\n",
      "Copying images into  sashimi\n",
      "\n",
      "Copying images into  scallops\n",
      "\n",
      "Copying images into  seaweed_salad\n",
      "\n",
      "Copying images into  shrimp_and_grits\n",
      "\n",
      "Copying images into  spaghetti_bolognese\n",
      "\n",
      "Copying images into  spaghetti_carbonara\n",
      "\n",
      "Copying images into  spring_rolls\n",
      "\n",
      "Copying images into  steak\n",
      "\n",
      "Copying images into  strawberry_shortcake\n",
      "\n",
      "Copying images into  sushi\n",
      "\n",
      "Copying images into  tacos\n",
      "\n",
      "Copying images into  takoyaki\n",
      "\n",
      "Copying images into  tiramisu\n",
      "\n",
      "Copying images into  tuna_tartare\n",
      "\n",
      "Copying images into  waffles\n",
      "Copying Done!\n"
     ]
    }
   ],
   "source": [
    "#getting test data\n",
    "prepare_data('food_data/food-101/meta/test.txt', 'food_data/food-101/images', 'food_data/food-101/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ad0392-9fdf-44b7-9441-915d0f57ee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples in train folder\n",
      "75750\n"
     ]
    }
   ],
   "source": [
    "#checking amount of images in train folders\n",
    "train_files = sum([len(files) for i, j, files in os.walk(\"food_data/food-101/train\")])\n",
    "print(\"Total number of samples in train folder\")\n",
    "print(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aff59fb-511f-4c69-9fc1-dc0575428bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples in test folder\n",
      "25250\n"
     ]
    }
   ],
   "source": [
    "#checking amount of images in test folders\n",
    "test_files = sum([len(files) for i, j, files in os.walk(\"food_data/food-101/test\")])\n",
    "print(\"Total number of samples in test folder\")\n",
    "print(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3239c249-3d69-44ef-ace7-0b244ae426d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple_pie',\n",
       " 'baby_back_ribs',\n",
       " 'baklava',\n",
       " 'beef_carpaccio',\n",
       " 'beef_tartare',\n",
       " 'beet_salad',\n",
       " 'beignets',\n",
       " 'bibimbap',\n",
       " 'bread_pudding',\n",
       " 'breakfast_burrito',\n",
       " 'bruschetta',\n",
       " 'caesar_salad',\n",
       " 'cannoli',\n",
       " 'caprese_salad',\n",
       " 'carrot_cake',\n",
       " 'ceviche',\n",
       " 'cheese_plate',\n",
       " 'cheesecake',\n",
       " 'chicken_curry',\n",
       " 'chicken_quesadilla',\n",
       " 'chicken_wings',\n",
       " 'chocolate_cake',\n",
       " 'chocolate_mousse',\n",
       " 'churros',\n",
       " 'clam_chowder',\n",
       " 'club_sandwich',\n",
       " 'crab_cakes',\n",
       " 'creme_brulee',\n",
       " 'croque_madame',\n",
       " 'cup_cakes',\n",
       " 'deviled_eggs',\n",
       " 'donuts',\n",
       " 'dumplings',\n",
       " 'edamame',\n",
       " 'eggs_benedict',\n",
       " 'escargots',\n",
       " 'falafel',\n",
       " 'filet_mignon',\n",
       " 'fish_and_chips',\n",
       " 'foie_gras',\n",
       " 'french_fries',\n",
       " 'french_onion_soup',\n",
       " 'french_toast',\n",
       " 'fried_calamari',\n",
       " 'fried_rice',\n",
       " 'frozen_yogurt',\n",
       " 'garlic_bread',\n",
       " 'gnocchi',\n",
       " 'greek_salad',\n",
       " 'grilled_cheese_sandwich',\n",
       " 'grilled_salmon',\n",
       " 'guacamole',\n",
       " 'gyoza',\n",
       " 'hamburger',\n",
       " 'hot_and_sour_soup',\n",
       " 'hot_dog',\n",
       " 'huevos_rancheros',\n",
       " 'hummus',\n",
       " 'ice_cream',\n",
       " 'lasagna',\n",
       " 'lobster_bisque',\n",
       " 'lobster_roll_sandwich',\n",
       " 'macaroni_and_cheese',\n",
       " 'macarons',\n",
       " 'miso_soup',\n",
       " 'mussels',\n",
       " 'nachos',\n",
       " 'omelette',\n",
       " 'onion_rings',\n",
       " 'oysters',\n",
       " 'pad_thai',\n",
       " 'paella',\n",
       " 'pancakes',\n",
       " 'panna_cotta',\n",
       " 'peking_duck',\n",
       " 'pho',\n",
       " 'pizza',\n",
       " 'pork_chop',\n",
       " 'poutine',\n",
       " 'prime_rib',\n",
       " 'pulled_pork_sandwich',\n",
       " 'ramen',\n",
       " 'ravioli',\n",
       " 'red_velvet_cake',\n",
       " 'risotto',\n",
       " 'samosa',\n",
       " 'sashimi',\n",
       " 'scallops',\n",
       " 'seaweed_salad',\n",
       " 'shrimp_and_grits',\n",
       " 'spaghetti_bolognese',\n",
       " 'spaghetti_carbonara',\n",
       " 'spring_rolls',\n",
       " 'steak',\n",
       " 'strawberry_shortcake',\n",
       " 'sushi',\n",
       " 'tacos',\n",
       " 'takoyaki',\n",
       " 'tiramisu',\n",
       " 'tuna_tartare',\n",
       " 'waffles']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total amount of classes (different foods images)\n",
    "foods_sorted = sorted(os.listdir('food_data/food-101/images'))\n",
    "foods_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a99314e0-fb8c-4b51-943e-0f1712152dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating miniature dataset for quick testing different model architectures\n",
    "def dataset_gen(food_list, src, dest):\n",
    "    if os.path.exists(dest):\n",
    "        rmtree(dest)\n",
    "    os.makedirs(dest)\n",
    "    for food_item in food_list :\n",
    "        print(\"Copying images into\",food_item)\n",
    "        copytree(os.path.join(src,food_item), os.path.join(dest,food_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fb94bdc-5887-4c75-986f-b65a9188791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing parameters for dataset_mini function to cteate mini datasets\n",
    "food_list = ['hot_dog','ravioli','tuna_tartare']\n",
    "src_train = 'food_data/food-101/train'\n",
    "dest_train = 'food_data/food-101/train_mini'\n",
    "src_test = 'food_data/food-101/test'\n",
    "dest_test = 'food_data/food-101/test_mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0f92bcb-1f45-4ea3-8fd4-f81ae3e5dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying images into hot_dog\n",
      "Copying images into ravioli\n",
      "Copying images into tuna_tartare\n"
     ]
    }
   ],
   "source": [
    "#creating mini train set\n",
    "dataset_gen(food_list, src_train, dest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c34fac0-dcac-4c7f-8d64-2d692be7a59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying images into hot_dog\n",
      "Copying images into ravioli\n",
      "Copying images into tuna_tartare\n"
     ]
    }
   ],
   "source": [
    "#creating mini train set\n",
    "dataset_gen(food_list, src_test, dest_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf520d14-1700-405d-88e8-eb0cc668e765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples in train folder\n",
      "2250\n"
     ]
    }
   ],
   "source": [
    "#checking amount of images in mini train folders\n",
    "print(\"Total number of samples in train folder\")\n",
    "train_files = sum([len(files) for i, j, files in os.walk(dest_train)])\n",
    "print(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4571c53b-33cc-4b81-a868-ad9899fa6525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples in test folder\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "#checking amount of images in mini test folders\n",
    "print(\"Total number of samples in test folder\")\n",
    "train_files = sum([len(files) for i, j, files in os.walk(dest_test)])\n",
    "print(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d577c830-8cfc-4df3-bade-532f3b5c5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 299, 299\n",
    "train_data_dir = 'food_data/food-101/train_mini'\n",
    "validation_data_dir = 'food_data/food-101/test_mini'\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da063ec9-f941-4fea-9ad4-45b373699b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b63d0d38-4528-4e47-af81-407f8c7d398c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf245ca7-e652-421d-8825-89f1b138f936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 750 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57487022-5ddf-4fe4-9b18-0375a38f82a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1 metric\n",
    "def f1(y_true, y_pred): \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    \n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19325151-bb48-4e0c-99cc-2a20265f62cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(width, height, depth, n_classes, regularization, activization, initializer = 'he_normal'):\n",
    "    \n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        input_shape = (depth, height, width)\n",
    "        chan_dim = 1\n",
    "    else:\n",
    "        input_shape = (height, width, depth)\n",
    "        chan_dim = -1\n",
    "    \n",
    "    model = Sequential(\n",
    "        [\n",
    "            layers.Conv2D(filters = 16, kernel_size = (7, 7), padding = 'valid', kernel_initializer = initializer,\n",
    "                        strides = (2, 2), kernel_regularizer = regularization, input_shape = input_shape),\n",
    "            \n",
    "            layers.Conv2D(filters = 32, kernel_size = (3, 3), padding = 'same', activation = activization,\n",
    "                        kernel_regularizer = regularization, kernel_initializer = initializer),\n",
    "            layers.BatchNormalization(axis = chan_dim),\n",
    "            layers.Conv2D(filters = 32, kernel_size = (3, 3), strides = (2, 2), padding = 'same', activation = activization,\n",
    "                        kernel_regularizer = regularization, kernel_initializer = initializer),\n",
    "            layers.BatchNormalization(axis = chan_dim),\n",
    "            layers.Dropout(0.2),\n",
    "            \n",
    "            layers.Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same', activation = activization,\n",
    "                        kernel_regularizer = regularization, kernel_initializer = initializer),\n",
    "            layers.BatchNormalization(axis = chan_dim),\n",
    "            layers.Conv2D(filters = 64, kernel_size = (3, 3), strides = (2, 2), padding = 'same', activation = activization,\n",
    "                        kernel_regularizer = regularization, kernel_initializer = initializer),\n",
    "            layers.BatchNormalization(axis = chan_dim),\n",
    "            layers.Dropout(0.2),\n",
    "            \n",
    "            layers.Conv2D(filters = 128, kernel_size = (3, 3), padding = 'same', activation = activization,\n",
    "                        kernel_regularizer = regularization, kernel_initializer = initializer),\n",
    "            layers.BatchNormalization(axis = chan_dim),\n",
    "            layers.Conv2D(filters = 128, kernel_size = (3, 3), strides = (2, 2), padding = 'same', activation = activization,\n",
    "                        kernel_regularizer = regularization, kernel_initializer = initializer),\n",
    "            layers.BatchNormalization(axis = chan_dim),\n",
    "            layers.Dropout(0.2),\n",
    "                     \n",
    "            layers.Flatten(),\n",
    "            layers.Dense(512, kernel_initializer = initializer, activation = activization),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            \n",
    "            layers.Dense(n_classes, activation = 'softmax'),\n",
    "\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0967e1be-4097-49f6-96dc-062a667e0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_comparison(optimizer1, optimizer2, model_for_comp1, n_epoch):\n",
    "    \n",
    "    model_for_comp2 = tf.keras.models.clone_model(model_for_comp1)\n",
    "    comparison_results = pd.DataFrame(index = ['Train loss', 'Train accuracy', 'Train f1', 'Train AUC', 'Validation loss', 'Validation accuracy', 'Validation f1', 'Validation AUC'])\n",
    "    metrics_list = ['accuracy', f1, AUC(name = 'AUC')]\n",
    "        \n",
    "    model_for_comp1.compile(optimizer = optimizer1, loss = 'categorical_crossentropy', metrics = metrics_list)\n",
    "    model_for_comp2.compile(optimizer = optimizer2, loss = 'categorical_crossentropy', metrics = metrics_list)\n",
    "        \n",
    "    history1 = model_for_comp1.fit(train_generator, validation_data = validation_generator, epochs = n_epoch, verbose = 0)\n",
    "    history2 = model_for_comp2.fit(train_generator, validation_data = validation_generator, epochs = n_epoch, verbose = 0)\n",
    "    \n",
    "    comparison_results['First optimizer'] = [history1.history['loss'][-1], history1.history['accuracy'][-1], history1.history['f1'][-1],\n",
    "                                            history1.history['AUC'][-1], history1.history['val_loss'][-1], history1.history['val_accuracy'][-1], \n",
    "                                            history1.history['val_f1'][-1], history1.history['val_AUC'][-1]]\n",
    "    \n",
    "    comparison_results['Second optimizer'] = [history1.history['loss'][-1], history1.history['accuracy'][-1], history1.history['f1'][-1],\n",
    "                                            history1.history['AUC'][-1], history1.history['val_loss'][-1], history1.history['val_accuracy'][-1], \n",
    "                                            history1.history['val_f1'][-1], history1.history['val_AUC'][-1]]\n",
    "\n",
    "    comparison_results.to_csv('Optimizer_comparison_results')\n",
    "    \n",
    "    return comparison_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "259360b6-919f-4d0d-804a-23a474be5991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_comparison(activation1, activation2, n_epoch):\n",
    "    \n",
    "    model_for_comp1 = CNN(299, 299, 3, 3, l2(0.00005), activation1)\n",
    "    model_for_comp2 = CNN(299, 299, 3, 3, l2(0.00005), activation2)\n",
    "        \n",
    "    comparison_results = pd.DataFrame(index = ['Train loss', 'Train accuracy', 'Train f1', 'Train AUC', 'Validation loss', 'Validation accuracy', 'Validation f1', 'Validation AUC'])\n",
    "    metrics_list = ['accuracy', f1, AUC(name = 'AUC')]\n",
    "    \n",
    "    model_for_comp1.compile(optimizer = Adam(learning_rate=0.001), loss = 'categorical_crossentropy', metrics = metrics_list)\n",
    "    model_for_comp2.compile(optimizer = Adam(learning_rate=0.001), loss = 'categorical_crossentropy', metrics = metrics_list)\n",
    "    \n",
    "    history1 = model_for_comp1.fit(train_generator, validation_data = validation_generator, epochs = n_epoch, verbose = 0)\n",
    "    history2 = model_for_comp2.fit(train_generator, validation_data = validation_generator, epochs = n_epoch, verbose = 0)\n",
    "    \n",
    "    comparison_results['First activation'] = [history1.history['loss'][-1], history1.history['accuracy'][-1], history1.history['f1'][-1],\n",
    "                                            history1.history['AUC'][-1], history1.history['val_loss'][-1], history1.history['val_accuracy'][-1], \n",
    "                                            history1.history['val_f1'][-1], history1.history['val_AUC'][-1]]\n",
    "    \n",
    "    comparison_results['Second activation'] = [history1.history['loss'][-1], history1.history['accuracy'][-1], history1.history['f1'][-1],\n",
    "                                            history1.history['AUC'][-1], history1.history['val_loss'][-1], history1.history['val_accuracy'][-1], \n",
    "                                            history1.history['val_f1'][-1], history1.history['val_AUC'][-1]]\n",
    "\n",
    "    comparison_results.to_csv('Activation_comparison_results')\n",
    "    \n",
    "    return comparison_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "251d2179-b190-413d-84bc-689690555652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RELU vs tanh\n",
    "activation_comparison = pd.read_csv('Activation_comparison_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbe86c91-4dce-4701-9d77-dbe4acf6944b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>First activation</th>\n",
       "      <th>Second activation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train loss</td>\n",
       "      <td>0.608128</td>\n",
       "      <td>0.608128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train accuracy</td>\n",
       "      <td>0.774667</td>\n",
       "      <td>0.774667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train f1</td>\n",
       "      <td>0.771333</td>\n",
       "      <td>0.771333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train AUC</td>\n",
       "      <td>0.915871</td>\n",
       "      <td>0.915871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Validation loss</td>\n",
       "      <td>0.846285</td>\n",
       "      <td>0.846285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Validation accuracy</td>\n",
       "      <td>0.716000</td>\n",
       "      <td>0.716000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Validation f1</td>\n",
       "      <td>0.709009</td>\n",
       "      <td>0.709009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Validation AUC</td>\n",
       "      <td>0.870251</td>\n",
       "      <td>0.870251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0  First activation  Second activation\n",
       "0           Train loss          0.608128           0.608128\n",
       "1       Train accuracy          0.774667           0.774667\n",
       "2             Train f1          0.771333           0.771333\n",
       "3            Train AUC          0.915871           0.915871\n",
       "4      Validation loss          0.846285           0.846285\n",
       "5  Validation accuracy          0.716000           0.716000\n",
       "6        Validation f1          0.709009           0.709009\n",
       "7       Validation AUC          0.870251           0.870251"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6aba96a7-a55f-4e79-8d8a-919f1ddbcd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam 0.001 learning rate vs SGD 0.0001 learning rate 0.9 momentum\n",
    "optimizer_comparison = pd.read_csv('Optimizer_comparison_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d6b06de-b049-4438-b690-e98c884bb237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>First optimizer</th>\n",
       "      <th>Second optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train loss</td>\n",
       "      <td>0.726076</td>\n",
       "      <td>0.726076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train accuracy</td>\n",
       "      <td>0.714222</td>\n",
       "      <td>0.714222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train f1</td>\n",
       "      <td>0.698641</td>\n",
       "      <td>0.698641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train AUC</td>\n",
       "      <td>0.877116</td>\n",
       "      <td>0.877116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Validation loss</td>\n",
       "      <td>0.904731</td>\n",
       "      <td>0.904731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Validation accuracy</td>\n",
       "      <td>0.661333</td>\n",
       "      <td>0.661333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Validation f1</td>\n",
       "      <td>0.656678</td>\n",
       "      <td>0.656678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Validation AUC</td>\n",
       "      <td>0.827453</td>\n",
       "      <td>0.827453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0  First optimizer  Second optimizer\n",
       "0           Train loss         0.726076          0.726076\n",
       "1       Train accuracy         0.714222          0.714222\n",
       "2             Train f1         0.698641          0.698641\n",
       "3            Train AUC         0.877116          0.877116\n",
       "4      Validation loss         0.904731          0.904731\n",
       "5  Validation accuracy         0.661333          0.661333\n",
       "6        Validation f1         0.656678          0.656678\n",
       "7       Validation AUC         0.827453          0.827453"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80fbefb1-3acf-4503-bd03-14a194d1c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#записи чекпоінтів та данних для графіків\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/\", histogram_freq=1)\n",
    "\n",
    "checkpoint_path = \"training/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97433f60-33a5-4358-bca0-0ffd89385095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 2.0583 - accuracy: 0.4467 - f1: 0.4394 - AUC: 0.6189\n",
      "Epoch 1: saving model to training\\cp-0001.ckpt\n",
      "36/36 [==============================] - 100s 3s/step - loss: 2.0583 - accuracy: 0.4467 - f1: 0.4394 - AUC: 0.6189 - val_loss: 1.6624 - val_accuracy: 0.4387 - val_f1: 0.4073 - val_AUC: 0.6174\n",
      "Epoch 2/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.2237 - accuracy: 0.5396 - f1: 0.5201 - AUC: 0.7203\n",
      "Epoch 2: saving model to training\\cp-0002.ckpt\n",
      "36/36 [==============================] - 98s 3s/step - loss: 1.2237 - accuracy: 0.5396 - f1: 0.5201 - AUC: 0.7203 - val_loss: 1.2263 - val_accuracy: 0.5160 - val_f1: 0.5034 - val_AUC: 0.6961\n",
      "Epoch 3/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.1429 - accuracy: 0.5591 - f1: 0.5381 - AUC: 0.7378\n",
      "Epoch 3: saving model to training\\cp-0003.ckpt\n",
      "36/36 [==============================] - 97s 3s/step - loss: 1.1429 - accuracy: 0.5591 - f1: 0.5381 - AUC: 0.7378 - val_loss: 1.1280 - val_accuracy: 0.5613 - val_f1: 0.5402 - val_AUC: 0.7296\n",
      "Epoch 4/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.0813 - accuracy: 0.5818 - f1: 0.5664 - AUC: 0.7571\n",
      "Epoch 4: saving model to training\\cp-0004.ckpt\n",
      "36/36 [==============================] - 98s 3s/step - loss: 1.0813 - accuracy: 0.5818 - f1: 0.5664 - AUC: 0.7571 - val_loss: 1.1284 - val_accuracy: 0.5813 - val_f1: 0.5566 - val_AUC: 0.7388\n",
      "Epoch 5/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.9982 - accuracy: 0.6133 - f1: 0.5877 - AUC: 0.7833\n",
      "Epoch 5: saving model to training\\cp-0005.ckpt\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.9982 - accuracy: 0.6133 - f1: 0.5877 - AUC: 0.7833 - val_loss: 1.1393 - val_accuracy: 0.5547 - val_f1: 0.5305 - val_AUC: 0.7222\n",
      "Epoch 6/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.9483 - accuracy: 0.6382 - f1: 0.6272 - AUC: 0.8085\n",
      "Epoch 6: saving model to training\\cp-0006.ckpt\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.9483 - accuracy: 0.6382 - f1: 0.6272 - AUC: 0.8085 - val_loss: 1.0065 - val_accuracy: 0.5827 - val_f1: 0.5557 - val_AUC: 0.7729\n",
      "Epoch 7/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.9257 - accuracy: 0.6578 - f1: 0.6427 - AUC: 0.8193\n",
      "Epoch 7: saving model to training\\cp-0007.ckpt\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.9257 - accuracy: 0.6578 - f1: 0.6427 - AUC: 0.8193 - val_loss: 0.9618 - val_accuracy: 0.6160 - val_f1: 0.6094 - val_AUC: 0.7905\n",
      "Epoch 8/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.9140 - accuracy: 0.6507 - f1: 0.6294 - AUC: 0.8211\n",
      "Epoch 8: saving model to training\\cp-0008.ckpt\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.9140 - accuracy: 0.6507 - f1: 0.6294 - AUC: 0.8211 - val_loss: 0.8458 - val_accuracy: 0.6747 - val_f1: 0.6649 - val_AUC: 0.8362\n",
      "Epoch 9/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.8440 - accuracy: 0.6782 - f1: 0.6764 - AUC: 0.8449\n",
      "Epoch 9: saving model to training\\cp-0009.ckpt\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.8440 - accuracy: 0.6782 - f1: 0.6764 - AUC: 0.8449 - val_loss: 0.9577 - val_accuracy: 0.6627 - val_f1: 0.6516 - val_AUC: 0.8205\n",
      "Epoch 10/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.7512 - accuracy: 0.7129 - f1: 0.7052 - AUC: 0.8750\n",
      "Epoch 10: saving model to training\\cp-0010.ckpt\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7512 - accuracy: 0.7129 - f1: 0.7052 - AUC: 0.8750 - val_loss: 0.8368 - val_accuracy: 0.6947 - val_f1: 0.6931 - val_AUC: 0.8541\n",
      "Epoch 11/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.7504 - accuracy: 0.7116 - f1: 0.6963 - AUC: 0.8718\n",
      "Epoch 11: saving model to training\\cp-0011.ckpt\n",
      "36/36 [==============================] - 98s 3s/step - loss: 0.7504 - accuracy: 0.7116 - f1: 0.6963 - AUC: 0.8718 - val_loss: 0.9451 - val_accuracy: 0.6440 - val_f1: 0.6378 - val_AUC: 0.8222\n",
      "Epoch 12/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.7373 - f1: 0.7266 - AUC: 0.8941\n",
      "Epoch 12: saving model to training\\cp-0012.ckpt\n",
      "36/36 [==============================] - 99s 3s/step - loss: 0.6928 - accuracy: 0.7373 - f1: 0.7266 - AUC: 0.8941 - val_loss: 0.7668 - val_accuracy: 0.6960 - val_f1: 0.6999 - val_AUC: 0.8654\n",
      "Epoch 13/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.6676 - accuracy: 0.7578 - f1: 0.7448 - AUC: 0.8996\n",
      "Epoch 13: saving model to training\\cp-0013.ckpt\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6676 - accuracy: 0.7578 - f1: 0.7448 - AUC: 0.8996 - val_loss: 0.9500 - val_accuracy: 0.6507 - val_f1: 0.6449 - val_AUC: 0.8382\n",
      "Epoch 14/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.6469 - accuracy: 0.7631 - f1: 0.7604 - AUC: 0.9066\n",
      "Epoch 14: saving model to training\\cp-0014.ckpt\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6469 - accuracy: 0.7631 - f1: 0.7604 - AUC: 0.9066 - val_loss: 0.8469 - val_accuracy: 0.6960 - val_f1: 0.6920 - val_AUC: 0.8556\n",
      "Epoch 15/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.5991 - accuracy: 0.7760 - f1: 0.7769 - AUC: 0.9200\n",
      "Epoch 15: saving model to training\\cp-0015.ckpt\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.5991 - accuracy: 0.7760 - f1: 0.7769 - AUC: 0.9200 - val_loss: 0.8582 - val_accuracy: 0.6880 - val_f1: 0.6808 - val_AUC: 0.8492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: the_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: the_model\\assets\n"
     ]
    }
   ],
   "source": [
    "#resulting model\n",
    "metrics_list = ['accuracy', f1, AUC(name = 'AUC')]\n",
    "the_model = CNN(299, 299, 3, 3, l2(0.00005), 'relu')\n",
    "the_model.compile(optimizer = Adam(learning_rate=0.001), loss = 'categorical_crossentropy', metrics = metrics_list)\n",
    "history = the_model.fit(train_generator, validation_data = validation_generator, epochs = 15, verbose = 1, callbacks = [tb_callback, cp_callback])\n",
    "the_model.save(f'the_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3e4cca0-3fdd-4960-bfbd-7ae965b25a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-335592807f03371e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-335592807f03371e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir './logs' --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a5691-f4d5-4833-9a3c-f7c8a52e1e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
