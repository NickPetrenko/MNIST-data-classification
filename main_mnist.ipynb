{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0fe272c-6bbc-4487-8046-f260a18e422b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Лабораторна робота №3\n",
    "# 31 варіант\n",
    "## з дисципліни ІСППР\n",
    "### виконав студент 3 курсу, групи КА-95, Петренко Микола¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5c8777-987e-4828-83c8-f9c2d096d7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Админ\\Python310\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.datasets import mnist\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm, trange #progress bars\n",
    "import cv2\n",
    "%load_ext tensorboard\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec0c76d-bf11-4415-be32-5decb1e45f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "(train_X, train_y), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f0d2dde-23bc-4107-9a7c-c9ba623ad36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#some visualization\n",
    "for i in range(9):  \n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(train_X[i], cmap = plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa174ba3-592e-4a52-82fc-3c7fcfed2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting initial training data into new train and validating datasets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb71543-de4d-41e6-9144-cec06f72d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping our data in 2d array, each data point corresponds to 'brightness' of pixel on initial 28x28 image\n",
    "X_train = X_train.reshape(len(X_train), 784) #784 = 28*28\n",
    "X_valid = X_valid.reshape(len(X_valid), 784)\n",
    "X_test = X_test.reshape(len(X_test), 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a1384a-ff7a-48d2-bf1f-99f42ccac59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalising data (to range (0, 1)) for easier training\n",
    "max_val = 255 #255 corresponds to 'brightest' pixel (white) so there is no value higher\n",
    "\n",
    "X_train = X_train.astype('float64')\n",
    "X_valid = X_valid.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "\n",
    "X_train /= max_val\n",
    "X_valid /= max_val\n",
    "X_test /= max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e8388b8-751b-49af-b78b-cbf8fe749b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting labels to set of arrays with only zeroes and ones each of them corresponding to number from 0 to 9\n",
    "num_classes = 10 #amount of numbers from 0 to 9\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# y_valid = np.argmax(y_valid, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aaf8444-190c-4d56-9ffa-498535f9b0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fb37e1a-206c-42fb-b660-a65893b57652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "y_train[0] #as we can see this array corresponds to 3 because it has 1 in fourth place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a17d35b8-487d-4945-b07f-d907289db4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model imputs\n",
    "X = tf.placeholder(tf.float32, shape = [None, 784], name='x-input')\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 10], name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74bb4b95-026f-40d4-901d-8ac555dfd236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating basic one layer model\n",
    "def basic(x):\n",
    "    logits = tf.compat.v1.layers.dense(inputs = x, units = 10, kernel_initializer = tf.random.normal)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9801be6-7d0c-4276-82cf-62d7bb206441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating deep model with multiple relu layers\n",
    "def deep_relu(x):\n",
    "    \n",
    "    w1 = tf.compat.v1.get_variable(name = 'w1_relu', shape = [784, 256], initializer = tf.compat.v1.initializers.he_normal())\n",
    "    b1 = tf.Variable(tf.zeros([256]))\n",
    "    h1_ = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "    h1 = tf.compat.v1.layers.dropout(h1_, rate = 0.1)\n",
    "    \n",
    "    w2 = tf.compat.v1.get_variable(name = 'w2_relu', shape = [256, 128], initializer = tf.compat.v1.initializers.he_normal())\n",
    "    b2 = tf.Variable(tf.zeros([128]))\n",
    "    h2_ = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
    "    h2 = tf.compat.v1.layers.dropout(h2_, rate = 0.1)\n",
    "\n",
    "    w3 = tf.compat.v1.get_variable(name = 'w3_relu', shape = [128, 10], initializer = tf.compat.v1.initializers.he_normal())\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "    logits_ = tf.matmul(h2, w3) + b3\n",
    "    logits = tf.compat.v1.layers.dropout(logits_, rate = 0.1)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6049880e-564e-4dad-a11e-21ab686fe830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating deep model with multiple tanh layers\n",
    "def deep_tanh(x):\n",
    "    \n",
    "    w1 = tf.compat.v1.get_variable(name = 'w1_tanh', shape = [784, 256], initializer = tf.compat.v1.keras.initializers.glorot_normal(), regularizer = tf.keras.regularizers.L1())\n",
    "    b1 = tf.Variable(tf.zeros([256]))\n",
    "    h1 = tf.nn.tanh(tf.matmul(x, w1) + b1)\n",
    "    \n",
    "    w2 = tf.compat.v1.get_variable(name = 'w2_tanh', shape = [256, 128], initializer = tf.compat.v1.keras.initializers.glorot_normal(), regularizer = tf.keras.regularizers.L1())\n",
    "    b2 = tf.Variable(tf.zeros([128]))\n",
    "    h2 = tf.nn.tanh(tf.matmul(h1, w2) + b2)\n",
    "    \n",
    "    w3 = tf.compat.v1.get_variable(name = 'w3_tanh', shape = [128, 10], initializer = tf.compat.v1.keras.initializers.glorot_normal(), regularizer = tf.keras.regularizers.L1())\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "    logits= tf.matmul(h2, w3) + b3\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "246aa4f5-ce1c-4ed5-b10c-37eed25e519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating deep model with leaky_relu & elu layers\n",
    "def relu_var(x):\n",
    "    \n",
    "    w1 = tf.compat.v1.get_variable(name = 'w1_var_relu', shape = [784, 256], initializer = tf.compat.v1.initializers.he_normal(), regularizer = tf.keras.regularizers.L1())\n",
    "    b1 = tf.Variable(tf.zeros([256]))\n",
    "    h1 = tf.nn.leaky_relu(tf.matmul(x, w1) + b1)\n",
    "    \n",
    "    w2 = tf.compat.v1.get_variable(name = 'w2_var_relu', shape = [256, 128], initializer = tf.compat.v1.initializers.he_normal(), regularizer = tf.keras.regularizers.L1())\n",
    "    b2 = tf.Variable(tf.zeros([128]))\n",
    "    h2 = tf.nn.elu(tf.matmul(h1, w2) + b2)\n",
    "    \n",
    "    w3 = tf.compat.v1.get_variable(name = 'w3_var_relu', shape = [128, 10], initializer = tf.compat.v1.initializers.he_normal(), regularizer = tf.keras.regularizers.L1())\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "    logits= tf.matmul(h2, w3) + b3\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31db92bd-b8f4-49e6-8b5d-22457eab1183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating deep model with multiple tanh layers & batch normalization\n",
    "def deep_tanh_norm(x):\n",
    "    \n",
    "    bn0 = tf.compat.v1.layers.BatchNormalization()\n",
    "    x = bn0.apply(x)\n",
    "    \n",
    "    bn1 = tf.compat.v1.layers.BatchNormalization()\n",
    "    w1 = tf.compat.v1.get_variable(name = 'w1_tanh_norm', shape = [784, 256], initializer = tf.compat.v1.keras.initializers.glorot_normal())\n",
    "    b1 = tf.Variable(tf.zeros([256]))\n",
    "    h1_ = tf.nn.tanh(tf.matmul(x, w1) + b1)\n",
    "    h1 = bn1.apply(h1_)\n",
    "    \n",
    "    bn2 = tf.compat.v1.layers.BatchNormalization()\n",
    "    w2 = tf.compat.v1.get_variable(name = 'w2_tanh_norm', shape = [256, 128], initializer = tf.compat.v1.keras.initializers.glorot_normal())\n",
    "    b2 = tf.Variable(tf.zeros([128]))\n",
    "    h2_ = tf.nn.tanh(tf.matmul(h1, w2) + b2)\n",
    "    h2 = bn2.apply(h2_)\n",
    "    \n",
    "    bn3 = tf.compat.v1.layers.BatchNormalization()\n",
    "    w3 = tf.compat.v1.get_variable(name = 'w3_tanh_norm', shape = [128, 10], initializer = tf.compat.v1.keras.initializers.glorot_normal())\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "    logits_ = tf.matmul(h2, w3) + b3\n",
    "    logits = bn3.apply(logits_)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bc9175d-4c9c-412c-ae56-c9e18a63dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting logits\n",
    "model1 = basic(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f09b051-bfd8-4595-b33b-a0a8a69dfdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting logits\n",
    "model2 = deep_relu(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6ebcf11-77ee-46f0-9d82-7421170ff7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting logits\n",
    "model3 = deep_tanh(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "168bd278-7013-45ca-a8c7-e0b180b11947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting logits\n",
    "model4 = relu_var(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e11ad2d9-b540-4494-811b-250ba6103a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting logits\n",
    "model5 = deep_tanh_norm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "912bb2f9-f04c-45aa-8718-661542e46cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining hyperparameters\n",
    "learning_rate_list = [0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "epoch = 50\n",
    "batch_size = 1000\n",
    "iteration = len(X_train) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8c87ab3-d986-4779-a679-68861a7e5959",
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "correct_prediction1 = tf.equal(tf.argmax(tf.nn.softmax(model1), 1), tf.argmax(Y, 1))\n",
    "correct_prediction2 = tf.equal(tf.argmax(tf.nn.softmax(model2), 1), tf.argmax(Y, 1))\n",
    "correct_prediction3 = tf.equal(tf.argmax(tf.nn.softmax(model3), 1), tf.argmax(Y, 1))\n",
    "correct_prediction4 = tf.equal(tf.argmax(tf.nn.softmax(model4), 1), tf.argmax(Y, 1))\n",
    "correct_prediction5 = tf.equal(tf.argmax(tf.nn.softmax(model5), 1), tf.argmax(Y, 1))\n",
    "\n",
    "accuracy1 = tf.reduce_mean(tf.cast(correct_prediction1, \"float\"))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, \"float\"))\n",
    "accuracy3 = tf.reduce_mean(tf.cast(correct_prediction3, \"float\"))\n",
    "accuracy4 = tf.reduce_mean(tf.cast(correct_prediction4, \"float\"))\n",
    "accuracy5 = tf.reduce_mean(tf.cast(correct_prediction5, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc5e4a25-958e-4e10-b293-8462527ddad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframes to save training records\n",
    "training_log11 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log12 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log13 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log14 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "\n",
    "training_log21 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log22 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log23 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log24 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "\n",
    "training_log31 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log32 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log33 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log34 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "\n",
    "training_log41 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log42 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log43 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log44 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "\n",
    "training_log51 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log52 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log53 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "training_log54 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate'])\n",
    "\n",
    "scores = pd.DataFrame(index = ['F1', 'AUC', 'Validation accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39afb936-fb4e-48a5-948d-ad92b5f4d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #cleaning directory with previous tensorboard logs\n",
    "# tbdir = './tblogs'\n",
    "\n",
    "# for filename in os.listdir(tbdir):\n",
    "#     file_path = os.path.join(tbdir, filename)\n",
    "#     try:\n",
    "#         if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "#             os.unlink(file_path)\n",
    "#         elif os.path.isdir(file_path):\n",
    "#             shutil.rmtree(file_path)\n",
    "#     except Exception as e:\n",
    "#         print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c66b887-105d-4219-b0ef-635c634fbd0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5dd2d363b64de69ffa3b3b8a24e508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92a57b682ac4c2ebec5652423bbc4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8a57e3c2cb494eb1a85098f465c79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373cda53cea54a2fb1d794abe910f8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce572a16cb341099abdcb6c5e7e97c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model1 with Adam optimizer & MSE cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model1_with_Adam_optimizer_and_MSE_cost', accuracy1)\n",
    "cost = tf.reduce_mean(tf.square(model1 - Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model1_with_Adam_optimizer_and_MSE_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "     \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model1/adam-mse/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model1/adam-mse/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model1/adam-mse/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model1/adam-mse/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model1/adam-mse/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "                \n",
    "            # # save_path   = saver.save(sess, 'model1-adam-mse-lr{}'.format(lr), write_meta_graph = False, write_state = False)                                \n",
    "            cur_val_acc, summary = sess.run([accuracy1, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "            \n",
    "        training_log11['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        \n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "809986b4-4ffa-42c4-8aab-11bc055a5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d9a9f86-1edf-4639-bb94-1ae6ae0c78df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model1-adam-mse-lr0.02\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model1-adam-mse-lr0.02')\n",
    "    preds = tf.nn.softmax(model1)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model1-adam-mse'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy1.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc61ba47-c4c6-459a-9c01-6ac1e073c25d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23e3662c770457d9586a6fcc66335b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de745085d824313bb778ffe81f9d21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f8b5c7796046f2a319cfc08c3e40fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee52f5bcc0a4977ab90e1ae076ad48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15068bdda0ab463baa2e1d1e5be67f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model1 with gradient descent optimizer & MSE cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model1_with_Gradient_Descent_optimizer_and_MSE_cost', accuracy1)\n",
    "cost = tf.reduce_mean(tf.square(model1 - Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model1_with_Gradient_Descent_optimizer_and_MSE_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model1/graddesc-mse/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model1/graddesc-mse/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model1/graddesc-mse/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model1/graddesc-mse/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model1/graddesc-mse/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "            \n",
    "            # save_path  = saver.save(sess, 'model1-graddesc-mse-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy1, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "                \n",
    "        training_log12['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e04a2aa7-fe30-4402-8e7a-8eb0e5487473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b289e2d-fad2-4ba5-b33e-3b818c521797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model1-graddesc-mse-lr0.05\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model1-graddesc-mse-lr0.05')\n",
    "    preds = tf.nn.softmax(model1)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model1-graddesc-mse'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy1.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2921391-bb66-40cc-a6fa-0f28a0284f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94c84afbfd2483da3c697c76ed927d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce7616db3704b74b68042d7ce16c0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4106d22fb334476fbea54f0aeae69fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ca8bc24e884584a3ef9c4c42e44874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8d8cb6ce54480ca8701e8399a39e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model1 with gradient descent optimizer & cross entropy cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model1_with_Gradient_Descent_optimizer_and_Cross_entropy_cost', accuracy1)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model1, labels = Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model1_with_Gradient_Descent_optimizer_and_Cross_entropy_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model1/graddesc-crossentr/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model1/graddesc-crossentr/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model1/graddesc-crossentr/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model1/graddesc-crossentr/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model1/graddesc-crossentr/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "            \n",
    "            # save_path  = saver.save(sess, 'model1-graddesc-crossentr-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy1, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "        \n",
    "        training_log13['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb888eb1-31e9-4f92-847a-e63717817432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37e14ff8-4417-46a7-83f3-e53d25e19429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model1-graddesc-crossentr-lr0.05\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model1-graddesc-crossentr-lr0.05')\n",
    "    preds = tf.nn.softmax(model1)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model1-graddesc-crossentr'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy1.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ab38898-4ae2-46d4-bcef-32cb2e201097",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505967028ed94044916a94209bac3199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6feb0efd273d402c88102ad02922ff87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8145f61ba3e642f1a6595810dead8966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e883a28fb34b878837b68ccf987ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3c437939f04c5b9d34ae000a5c1cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model1 with Adam optimizer & cross entropy cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model1_with_Adam_optimizer_and_Cross_entropy_cost', accuracy1)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model1, labels = Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model1_with_Adam_optimizer_and_Cross_entropy_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model1/adam-crossentr/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model1/adam-crossentr/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model1/adam-crossentr/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model1/adam-crossentr/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model1/adam-crossentr/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "                \n",
    "            # save_path  = saver.save(sess, 'model1-adam-crossentr-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy1, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "                \n",
    "        training_log14['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41557271-1b93-4e9f-a94a-3436a2f44ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb8b9d7a-ff8b-49a5-a136-96638955fc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model1-adam-crossentr-lr0.02\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model1-adam-crossentr-lr0.02')\n",
    "    preds = tf.nn.softmax(model1)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model1-adam-crossentr'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy1.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b02bf865-42ce-4684-9d3c-ce9412b31767",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da4aae188f646819a4880dd10c50dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61e7554456741c0aba413a05c64bcaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a565ae102e4a21874906c18ad156d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a56f11139d14fa6bb8527d671761317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b8b433f8a14b3e992442f3739e9cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model2 with Adam optimizer & MSE cost\n",
    "best_params21 = pd.DataFrame(index = ['Accuracy on validation data', 'Average loss', 'Learning rate', 'Optimizer', 'Cost function'])\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model2_with_Adam_optimizer_and_MSE_cost', accuracy2)\n",
    "cost = tf.reduce_mean(tf.square(model2 - Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model2_with_Adam_optimizer_and_MSE_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "     \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model2/adam-mse/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model2/adam-mse/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model2/adam-mse/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model2/adam-mse/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model2/adam-mse/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "                            \n",
    "            # save_path  = saver.save(sess, 'model2-adam-mse-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy2, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "                \n",
    "        training_log21['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        j += 1\n",
    "           \n",
    "for col in training_log21.columns:\n",
    "    if training_log21[col].loc['Average loss'] == training_log21.loc['Average loss'].values.min():\n",
    "        best_params21['Model 2'] = [training_log21[col].values[0], training_log21[col].values[1], training_log21[col].values[2], 'Adam', 'MSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09648bea-ca3c-413f-8aac-24c6fa03a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b313644-4904-4b1f-acf5-73d06f3766ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model2-adam-mse-lr0.01\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model2-adam-mse-lr0.01')\n",
    "    preds = tf.nn.softmax(model2)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model2-adam-mse'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy2.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2436d06-91ac-4ba3-97ca-9a51bdd99e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9860b6cdeb482390e2f4cb2170dd4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1532b094d5ed4ac2b47c0d418a1e027b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9264923951c44b6d824c5bb1390aa5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76f2f2a6724460697a15dde047bfca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6ebdb096be46c2b3476508b68a1c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model2 with gradient descent optimizer & MSE cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model2_with_Gradient_Descent_optimizer_and_MSE_cost', accuracy2)\n",
    "cost = tf.reduce_mean(tf.square(model2 - Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model2_with_Gradient_Descent_optimizer_and_MSE_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model2/graddesc-mse/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model2/graddesc-mse/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model2/graddesc-mse/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model2/graddesc-mse/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model2/graddesc-mse/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "            \n",
    "            # save_path  = saver.save(sess, 'model2-graddesc-mse-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy2, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)   \n",
    "                \n",
    "        training_log22['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51a6e517-60b2-4a28-b292-a1b0d6e4635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "024101a9-b29b-4f87-a5d6-979e30fb6846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model2-graddesc-mse-lr0.05\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model2-graddesc-mse-lr0.05')\n",
    "    preds = tf.nn.softmax(model2)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model2-graddesc-mse'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy2.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98a2ea18-816b-408e-893b-25924fdf8d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7adb92732b1a4e98b0fc45fc7b1b3842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d31aa2442b94971a70294aa91d39edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bfe8032c7744de936cc203156e680b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2d39609b8d47838cc1863179d9b6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e6cc550ca44edca559f1fd22bf104a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model1 with gradient descent optimizer & cross entropy cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model2_with_Gradient_Descent_optimizer_and_Cross_entropy_cost', accuracy2)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model2, labels = Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model2_with_Gradient_Descent_optimizer_and_Cross_entropy_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model2/graddesc-crossentr/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model2/graddesc-crossentr/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model2/graddesc-crossentr/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model2/graddesc-crossentr/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model2/graddesc-crossentr/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "            \n",
    "            # save_path  = saver.save(sess, 'model2-graddesc-crossentr-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy2, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "                \n",
    "        training_log23['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24124026-166b-4979-b248-3ff96b5b8261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7334b851-5107-4372-adb9-255ae6af4938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model2-graddesc-crossentr-lr0.05\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model2-graddesc-crossentr-lr0.05')\n",
    "    preds = tf.nn.softmax(model2)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model2-graddesc-crossentr'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy2.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e251f5a-dd7f-41c6-b288-34235d9682ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690abafe882944a4aa354f7172a97738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78076ebaf490458aa72f1ada1246bc26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9c3d4f4b124df38da00caec1cfc68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c5f6284dfc421391283a7ac925dd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8210aa4686204936872a53ecaeb7c340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model2 with Adam optimizer & cross entropy cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model2_with_Adam_optimizer_and_Cross_entropy_cost', accuracy2)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model2, labels = Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model2_with_Adam_optimizer_and_Cross_entropy_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model2/adam-crossentr/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model2/adam-crossentr/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model2/adam-crossentr/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model2/adam-crossentr/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model2/adam-crossentr/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "                \n",
    "            # save_path  = saver.save(sess, 'model2-adam-crossentr-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy2, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "                \n",
    "        training_log24['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf8b4145-6b85-4fb9-987c-54c7fc5a2ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b5188ff-db46-4686-8a04-ba3f555e7875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model2-adam-crossentr-lr0.01\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model2-adam-crossentr-lr0.01')\n",
    "    preds = tf.nn.softmax(model2)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model2-adam-crossentr'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy2.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b5db155-da80-4316-a9d8-af7ead4e70f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94521206138545f5a8ea8d552056164d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.data-00000-of-00001.tempstate6923177340213921996\n",
      "INFO:tensorflow:7600\n",
      "INFO:tensorflow:model3-adam-mse-lr0.01.index\n",
      "INFO:tensorflow:7600\n",
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1021a474bc44a4cb04036256947209c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.02.index\n",
      "INFO:tensorflow:3800\n",
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a657b39bfe3412a9110609c68672ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.03.index\n",
      "INFO:tensorflow:3800\n",
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba40eb42fa54215875de72e229466d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.04.index\n",
      "INFO:tensorflow:3800\n",
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a51aea81644235bf891e98d3db6913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.data-00000-of-00001\n",
      "INFO:tensorflow:3800\n",
      "INFO:tensorflow:model3-adam-mse-lr0.05.index\n",
      "INFO:tensorflow:3800\n"
     ]
    }
   ],
   "source": [
    "# training model3 with Adam optimizer & MSE cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model3_with_Adam_optimizer_and_MSE_cost', accuracy3)\n",
    "cost = tf.reduce_mean(tf.square(model3 - Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model3_with_Adam_optimizer_and_MSE_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "     \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model3/adam-mse/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model3/adam-mse/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model3/adam-mse/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model3/adam-mse/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model3/adam-mse/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "                            \n",
    "            # save_path  = saver.save(sess, 'model3-adam-mse-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy3, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "                \n",
    "        training_log31['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc404599-adac-4e13-8fed-69d4346c5c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74d8873c-f94c-4062-b7da-85b50759c01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model3-adam-mse-lr0.01\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model3-adam-mse-lr0.01')\n",
    "    preds = tf.nn.softmax(model3)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model3-adam-mse'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy3.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0615ec4-436f-49d7-8661-eae6a0a7d434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7914907348744345b4c71fbc445781bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6843f076b93a431a8bba506843ca83f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b267a02145b468085758c0cc5fb894b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec57e82dbda04f4783c89871c5c0a981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6326fa509b84142b491d519f0d2ef9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model3 with gradient descent optimizer & MSE cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model3_with_Gradient_Descent_optimizer_and_MSE_cost', accuracy3)\n",
    "cost = tf.reduce_mean(tf.square(model3 - Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model3_with_Gradient_Descent_optimizer_and_MSE_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model3/graddesc-mse/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model3/graddesc-mse/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model3/graddesc-mse/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model3/graddesc-mse/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model3/graddesc-mse/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "                            \n",
    "            # save_path  = saver.save(sess, 'model3-graddesc-mse-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy3, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "                \n",
    "        training_log32['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "549d91fd-26db-46df-a8d0-8efe0ae50bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c94e35d-226d-4860-b7be-8876885741c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model3-graddesc-mse-lr0.05\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model3-graddesc-mse-lr0.05')\n",
    "    preds = tf.nn.softmax(model3)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model3-graddesc-mse'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy3.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4ee4749-8ee1-4a10-95b9-5c95e2388c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d038ed44fa754e419e8830e5a1ffb585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a43840900bb4a618948d9e614d884e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2c661282e24531a885cdd5ab9c1c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b345495acb01409b85dc8775f17541a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2c0f7d6ea34ae9b6fa3866d2878bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model3 with gradient descent optimizer & cross entropy cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model3_with_Gradient_Descent_optimizer_and_Cross_entropy_cost', accuracy3)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model3, labels = Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model3_with_Gradient_Descent_optimizer_and_Cross_entropy_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model3/graddesc-crossentr/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model3/graddesc-crossentr/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model3/graddesc-crossentr/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model3/graddesc-crossentr/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model3/graddesc-crossentr/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "                \n",
    "            # save_path  = saver.save(sess, 'model3-graddesc-crossentr-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy3, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "                \n",
    "        training_log33['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66fdb568-e4aa-4e85-82f4-fbeb854308d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3149b47a-57a3-440c-9496-fa81eed10106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model3-graddesc-crossentr-lr0.05\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model3-graddesc-crossentr-lr0.05')\n",
    "    preds = tf.nn.softmax(model3)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model3-graddesc-crossentr'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy3.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5949e0f7-bde9-42d6-8c7c-df2fde318880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa9a51d1cf3425b8ae6f68c9c8ab900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7c211be2b34994bf46a78bf5a41a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e604298a3e074900818e0606de74345d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699cb3eea92f47e2999f1783ed18c850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b45b9259854ea19abbf182e9c78852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model3 with Adam optimizer & cross entopy cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model3_with_Adam_optimizer_and_Cross_entropy_cost', accuracy3)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model3, labels = Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model3_with_Adam_optimizer_and_Cross_entropy_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model3/adam-crossentr/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model3/adam-crossentr/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model3/adam-crossentr/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model3/adam-crossentr/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model3/adam-crossentr/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "                \n",
    "            # save_path  = saver.save(sess, 'model3-adam-crossentr-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy3, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "                \n",
    "        training_log34['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b82c107-24eb-4368-b42f-1518e08d5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a58d8ec2-c206-49e5-8f72-1d04b56a5f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model3-adam-crossentr-lr0.01\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model3-adam-crossentr-lr0.01')\n",
    "    preds = tf.nn.softmax(model3)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model3-adam-crossentr'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy3.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "41880997-4f5c-4871-8d17-62d5aa5f0368",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bca6223525453b9c928bc73bcdd7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25dcef3cd8546a6a0f7eb117b8fa54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bcab7534764dd5913401bdd0978328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf3ef8d76f944caa1aee3feb34a398f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9197746dd442238ecca692c5052384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model4 with Adam optimizer & MSE cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model4_with_Adam_optimizer_and_MSE_cost', accuracy4)\n",
    "cost = tf.reduce_mean(tf.square(model4 - Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model4_with_Adam_optimizer_and_MSE_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "     \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model4/adam-mse/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model4/adam-mse/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model4/adam-mse/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model4/adam-mse/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model4/adam-mse/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "                            \n",
    "            # save_path  = saver.save(sess, 'model4-adam-mse-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy4, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "            \n",
    "        training_log41['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        \n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9050ae61-258a-43d5-a1c5-72fcf0b7279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c0f72d2-8b49-47e7-8100-1a04d2fd81fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model1-adam-mse-lr0.01\n",
      "Test Accuracy : 0.0926\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model1-adam-mse-lr0.01')\n",
    "    print(\"Test Accuracy :\", accuracy4.eval({X: X_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7950aa2b-0da7-47ff-88ae-389611211b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c62387410ff43de86c236c2440608eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041bdbbe3fc242f5bf6d53ba3dc4c9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70dbac22c8ea4c43b4e6747bcaf5de36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d9a977eca04699870cc8282803be03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7bc2eb5b532475e91628e3ba7ab70ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model4 with gradient descent optimizer & MSE cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model4_with_Gradient_Descent_optimizer_and_MSE_cost', accuracy4)\n",
    "cost = tf.reduce_mean(tf.square(model4 - Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model4_with_Gradient_Descent_optimizer_and_MSE_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model4/graddesc-mse/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model4/graddesc-mse/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model4/graddesc-mse/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model4/graddesc-mse/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model4/graddesc-mse/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "            \n",
    "            # save_path  = saver.save(sess, 'model4-graddesc-mse-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy4, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "                \n",
    "        training_log42['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dca98f64-dc87-43e6-816d-be7ad850de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "39cf5369-9aa1-4685-8bf4-fcaf9593bdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model4-graddesc-mse-lr0.05\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model4-graddesc-mse-lr0.05')\n",
    "    preds = tf.nn.softmax(model4)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model4-graddesc-mse'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy4.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "074d1f8a-a59e-4653-b9aa-784182f83a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9dd3225ad54ecdb77997dfbc9d44e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ebc9a86b5a441d85a002d5796505d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac445776a52f454f85d9651a9a0d1fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bc3e05ada64ac99b51567d6e10afe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ddfa97afc04f52864a8890f87845c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model4 with gradient descent optimizer & cross entropy cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model4_with_Gradient_Descent_optimizer_and_Cross_entropy_cost', accuracy4)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model4, labels = Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model4_with_Gradient_Descent_optimizer_and_Cross_entropy_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model4/graddesc-crossentr/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model4/graddesc-crossentr/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model4/graddesc-crossentr/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model4/graddesc-crossentr/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model4/graddesc-crossentr/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "            \n",
    "            # save_path  = saver.save(sess, 'model4-graddesc-crossentr-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy4, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "        \n",
    "        training_log43['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "74b4cf58-592e-4031-9aac-7209129cb3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fb08f475-d4ca-4def-a5f7-a9c17a7d2708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model4-graddesc-crossentr-lr0.05\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model4-graddesc-crossentr-lr0.05')\n",
    "    preds = tf.nn.softmax(model4)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model4-graddesc-crossentr'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy4.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "62b7b5dc-7d39-4fc7-973b-c0202948f85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8928e15108042cf938e52148538fccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423c65511cbd4498ba272c4e4f87cd20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc25884feee7464b804c3635c17ecbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae7f6605375461486eee169c9a39dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2dbfbd1db86483f90b7de74e170002a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model4 with Adam optimizer & cross entropy cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model4_with_Adam_optimizer_and_Cross_entropy_cost', accuracy4)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model4, labels = Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model4_with_Adam_optimizer_and_Cross_entropy_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model4/adam-crossentr/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model4/adam-crossentr/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model4/adam-crossentr/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model4/adam-crossentr/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model4/adam-crossentr/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "                \n",
    "            # save_path  = saver.save(sess, 'model4-adam-crossentr-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy4, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "                \n",
    "        training_log44['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e13cae7-6491-4b2b-ac2d-8458c4f92985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f0d5a8f-a73e-41c7-80e6-ca031380723c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model4-adam-crossentr-lr0.01\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model4-adam-crossentr-lr0.01')\n",
    "    preds = tf.nn.softmax(model4)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model4-adam-crossentr'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy4.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1118ebe8-35e2-4ad4-9f49-68cf5b7f5ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1bede7b5c0448fe9094e66eeb44534c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96030eaadd2c4a3fa5aae1eb6e162f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaae601fbd8e464988e6faa8072fe296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f6d30f38e642318e837157ea716ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c231226ef3be4e989c72b473a1c69001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model5 with Adam optimizer & MSE cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model5_with_Adam_optimizer_and_MSE_cost', accuracy5)\n",
    "cost = tf.reduce_mean(tf.square(model5 - Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model5_with_Adam_optimizer_and_MSE_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "     \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model5/adam-mse/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model5/adam-mse/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model5/adam-mse/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model5/adam-mse/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model5/adam-mse/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "                            \n",
    "            # save_path  = saver.save(sess, 'model5-adam-mse-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy5, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "            \n",
    "        training_log51['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        \n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6453bd93-3000-48b0-add7-c17102fc6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "afb7d019-1337-42dd-8fc1-3cd7c51ec700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model5-adam-mse-lr0.01\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model5-adam-mse-lr0.01')\n",
    "    preds = tf.nn.softmax(model5)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model5-adam-mse'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy5.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "70037c5e-8672-435e-843c-799b0e44d0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bda816c25b5408f850958a23c3cc956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f225206ccd3647598c33c84f84932dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a43363f54a14fd0aff14942a90ae5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f115ba46a84f94b1b57d04240301f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63312138b67416e9c4592372c4a18e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model5 with gradient descent optimizer & MSE cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model5_with_Gradient_Descent_optimizer_and_MSE_cost', accuracy5)\n",
    "cost = tf.reduce_mean(tf.square(model5 - Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model5_with_Gradient_Descent_optimizer_and_MSE_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model5/graddesc-mse/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model5/graddesc-mse/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model5/graddesc-mse/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model5/graddesc-mse/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model5/graddesc-mse/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "                            \n",
    "            # save_path  = saver.save(sess, 'model5-graddesc-mse-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy5, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "                \n",
    "        training_log52['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "49c46336-e84d-458e-ad17-5468508049d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "276e3c64-6581-41f7-9eee-4f0177e8b445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model5-graddesc-mse-lr0.05\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model5-graddesc-mse-lr0.05')\n",
    "    preds = tf.nn.softmax(model5)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model5-graddesc-mse'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy5.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "418fce16-dcd6-42ef-b112-bb0cc3e9bea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e9bd7580d0487fbf828b17bce1a067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ffbc0338ea401280f3ddb7d5325d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1539e96a9d4ba7895861a684da08f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28db5901239c44c1b5d8007460cf9520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61431e92bf4d4486b5cd65ab252f16e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model5 with gradient descent optimizer & cross entropy cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model5_with_Gradient_Descent_optimizer_and_Cross_entropy_cost', accuracy5)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model5, labels = Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model5_with_Gradient_Descent_optimizer_and_Cross_entropy_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model5/graddesc-crossentr/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model5/graddesc-crossentr/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model5/graddesc-crossentr/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model5/graddesc-crossentr/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model5/graddesc-crossentr/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "            \n",
    "            # save_path  = saver.save(sess, 'model5-graddesc-crossentr-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy5, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "        \n",
    "        training_log53['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b9408b55-f0fe-4ec8-902d-66cc980202ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "714721fd-08dd-436d-9263-3893deb90bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model5-graddesc-crossentr-lr0.05\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model5-graddesc-crossentr-lr0.05')\n",
    "    preds = tf.nn.softmax(model5)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model5-graddesc-crossentr'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy5.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0a8e4ede-21c5-47a4-8f7c-cb4e4ed8ade3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa3c5486f354c289bd9caf7fd4b607d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7d38a82f084a59b8c69dc42b44398b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0d7912405f45758706fd03533e1c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4527c0e6c84573932fb64851aae6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Current learning rate: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd296c52b44a4462b5339f74ec69cf90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training model5 with Adam optimizer & cross entropy cost\n",
    "j = 1\n",
    "\n",
    "acc_summary = tf.summary.scalar('Accuracy_summary_for_model5_with_Adam_optimizer_and_Cross_entropy_cost', accuracy5)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model5, labels = Y))\n",
    "loss_summary = tf.summary.scalar('Loss_summary_for_model5_with_Adam_optimizer_and_Cross_entropy_cost', cost)\n",
    "merged = tf.summary.merge([acc_summary, loss_summary])\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(lr).minimize(cost)    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('Training model. Current learning rate: {:.2f}'.format(lr))\n",
    "    \n",
    "    outer_lvl = list(range(epoch))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        writer1 = tf.summary.FileWriter('tblogs/model5/adam-crossentr/lr0.01', sess.graph)\n",
    "        writer2 = tf.summary.FileWriter('tblogs/model5/adam-crossentr/lr0.02', sess.graph)\n",
    "        writer3 = tf.summary.FileWriter('tblogs/model5/adam-crossentr/lr0.03', sess.graph)\n",
    "        writer4 = tf.summary.FileWriter('tblogs/model5/adam-crossentr/lr0.04', sess.graph)\n",
    "        writer5 = tf.summary.FileWriter('tblogs/model5/adam-crossentr/lr0.05', sess.graph)\n",
    "        \n",
    "        sess.run(init)\n",
    "        for k in tqdm(outer_lvl, desc = 'Epoch progress'):\n",
    "            avg_loss = 0.\n",
    "            start = 0; end = batch_size\n",
    "        \n",
    "            for i in range(iteration):\n",
    "                _, loss, summary = sess.run([optimizer, cost, merged], feed_dict={X: X_train[start: end], Y: y_train[start: end]})\n",
    "                start += batch_size; end += batch_size\n",
    "                avg_loss += loss / iteration\n",
    "            \n",
    "            # save_path = saver.save(sess, 'model5-adam-crossentr-lr{}'.format(lr), write_meta_graph = False, write_state = False)                            \n",
    "            cur_val_acc, summary = sess.run([accuracy5, merged], feed_dict = {X: X_valid, Y: y_valid})\n",
    "            \n",
    "            if lr == 0.01:\n",
    "                writer1.add_summary(summary, k)\n",
    "            elif lr == 0.02:\n",
    "                writer2.add_summary(summary, k)\n",
    "            elif lr == 0.03:\n",
    "                writer3.add_summary(summary, k)\n",
    "            elif lr == 0.04:\n",
    "                writer4.add_summary(summary, k)\n",
    "            else:\n",
    "                writer5.add_summary(summary, k)\n",
    "                \n",
    "        training_log54['Fit №' + str(learning_rate_list.index(lr) + 1)] = [cur_val_acc, avg_loss, lr]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0c8c4b34-0db0-4e41-a34d-1a3e586050c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "# training_log54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "474f9a0c-1053-4376-899a-844052eedd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model5-adam-crossentr-lr0.01\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model5-adam-crossentr-lr0.01')\n",
    "    preds = tf.nn.softmax(model5)\n",
    "    preds_val = preds.eval({X: X_valid, Y: y_valid})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "    scores['model5-adam-crossentr'] = [f1_score(y_valid, preds_val, average = 'macro'), roc_auc_score(y_valid, preds_val, multi_class = 'ovr', average = 'macro'), accuracy5.eval({X: X_valid, Y: y_valid})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1143a544-7c01-49bd-bea3-5c885015f5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b490551074fe99c5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b490551074fe99c5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir './tblogs' #--host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fb614862-1dda-46bc-815c-a2cefb2c44ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1-adam-mse</th>\n",
       "      <th>model1-graddesc-mse</th>\n",
       "      <th>model1-graddesc-crossentr</th>\n",
       "      <th>model1-adam-crossentr</th>\n",
       "      <th>model2-adam-mse</th>\n",
       "      <th>model2-graddesc-mse</th>\n",
       "      <th>model2-graddesc-crossentr</th>\n",
       "      <th>model2-adam-crossentr</th>\n",
       "      <th>model3-adam-mse</th>\n",
       "      <th>model3-graddesc-mse</th>\n",
       "      <th>model3-graddesc-crossentr</th>\n",
       "      <th>model3-adam-crossentr</th>\n",
       "      <th>model4-graddesc-mse</th>\n",
       "      <th>model4-graddesc-crossentr</th>\n",
       "      <th>model4-adam-crossentr</th>\n",
       "      <th>model5-adam-mse</th>\n",
       "      <th>model5-graddesc-mse</th>\n",
       "      <th>model5-graddesc-crossentr</th>\n",
       "      <th>model5-adam-crossentr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.791969</td>\n",
       "      <td>0.177356</td>\n",
       "      <td>0.803749</td>\n",
       "      <td>0.926214</td>\n",
       "      <td>0.956630</td>\n",
       "      <td>0.902663</td>\n",
       "      <td>0.962943</td>\n",
       "      <td>0.991626</td>\n",
       "      <td>0.963471</td>\n",
       "      <td>0.893046</td>\n",
       "      <td>0.945995</td>\n",
       "      <td>0.995396</td>\n",
       "      <td>0.906089</td>\n",
       "      <td>0.956969</td>\n",
       "      <td>0.989828</td>\n",
       "      <td>0.983477</td>\n",
       "      <td>0.892981</td>\n",
       "      <td>0.959426</td>\n",
       "      <td>0.995131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.881876</td>\n",
       "      <td>0.543662</td>\n",
       "      <td>0.891245</td>\n",
       "      <td>0.958711</td>\n",
       "      <td>0.975770</td>\n",
       "      <td>0.945993</td>\n",
       "      <td>0.979406</td>\n",
       "      <td>0.995446</td>\n",
       "      <td>0.979787</td>\n",
       "      <td>0.940574</td>\n",
       "      <td>0.969978</td>\n",
       "      <td>0.997452</td>\n",
       "      <td>0.947892</td>\n",
       "      <td>0.976100</td>\n",
       "      <td>0.994412</td>\n",
       "      <td>0.990786</td>\n",
       "      <td>0.940573</td>\n",
       "      <td>0.977448</td>\n",
       "      <td>0.997297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation accuracy</th>\n",
       "      <td>0.791333</td>\n",
       "      <td>0.180750</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.956583</td>\n",
       "      <td>0.904250</td>\n",
       "      <td>0.963250</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.963750</td>\n",
       "      <td>0.894417</td>\n",
       "      <td>0.946583</td>\n",
       "      <td>0.995417</td>\n",
       "      <td>0.907333</td>\n",
       "      <td>0.957417</td>\n",
       "      <td>0.989833</td>\n",
       "      <td>0.983583</td>\n",
       "      <td>0.894250</td>\n",
       "      <td>0.959833</td>\n",
       "      <td>0.995167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model1-adam-mse  model1-graddesc-mse  \\\n",
       "F1                          0.791969             0.177356   \n",
       "AUC                         0.881876             0.543662   \n",
       "Validation accuracy         0.791333             0.180750   \n",
       "\n",
       "                     model1-graddesc-crossentr  model1-adam-crossentr  \\\n",
       "F1                                    0.803749               0.926214   \n",
       "AUC                                   0.891245               0.958711   \n",
       "Validation accuracy                   0.806667               0.927083   \n",
       "\n",
       "                     model2-adam-mse  model2-graddesc-mse  \\\n",
       "F1                          0.956630             0.902663   \n",
       "AUC                         0.975770             0.945993   \n",
       "Validation accuracy         0.956583             0.904250   \n",
       "\n",
       "                     model2-graddesc-crossentr  model2-adam-crossentr  \\\n",
       "F1                                    0.962943               0.991626   \n",
       "AUC                                   0.979406               0.995446   \n",
       "Validation accuracy                   0.963250               0.991667   \n",
       "\n",
       "                     model3-adam-mse  model3-graddesc-mse  \\\n",
       "F1                          0.963471             0.893046   \n",
       "AUC                         0.979787             0.940574   \n",
       "Validation accuracy         0.963750             0.894417   \n",
       "\n",
       "                     model3-graddesc-crossentr  model3-adam-crossentr  \\\n",
       "F1                                    0.945995               0.995396   \n",
       "AUC                                   0.969978               0.997452   \n",
       "Validation accuracy                   0.946583               0.995417   \n",
       "\n",
       "                     model4-graddesc-mse  model4-graddesc-crossentr  \\\n",
       "F1                              0.906089                   0.956969   \n",
       "AUC                             0.947892                   0.976100   \n",
       "Validation accuracy             0.907333                   0.957417   \n",
       "\n",
       "                     model4-adam-crossentr  model5-adam-mse  \\\n",
       "F1                                0.989828         0.983477   \n",
       "AUC                               0.994412         0.990786   \n",
       "Validation accuracy               0.989833         0.983583   \n",
       "\n",
       "                     model5-graddesc-mse  model5-graddesc-crossentr  \\\n",
       "F1                              0.892981                   0.959426   \n",
       "AUC                             0.940573                   0.977448   \n",
       "Validation accuracy             0.894250                   0.959833   \n",
       "\n",
       "                     model5-adam-crossentr  \n",
       "F1                                0.995131  \n",
       "AUC                               0.997297  \n",
       "Validation accuracy               0.995167  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all models scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "11da3890-e2dc-4e9a-b042-70321a3b794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1                     0.995396\n",
      "AUC                    0.997452\n",
      "Validation accuracy    0.995417\n",
      "Name: model3-adam-crossentr, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#defining best model\n",
    "for col in scores.columns:\n",
    "    if scores[col].loc['F1'] == scores.loc['F1'].values.max():\n",
    "        best_model = scores[col]\n",
    "        \n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b473a0c2-e2b3-48d0-9434-f51a6f4055b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model5-adam-crossentr-lr0.01\n",
      "For 9810 handwritten digit we have correct prediction from model. Gratz.\n"
     ]
    }
   ],
   "source": [
    "#restoring best model and predicting random image\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model5-adam-crossentr-lr0.01')\n",
    "    preds = tf.nn.softmax(model5)\n",
    "    preds_val = preds.eval({X: X_test, Y: y_test})\n",
    "    for i in range(len(preds_val)):\n",
    "        preds_val[i] = np.where(preds_val[i] < max(preds_val[i]), 0, 1)\n",
    "\n",
    "num = random.randint(0, len(y_test))\n",
    "if np.array_equal(preds_val[num], y_test[num]):\n",
    "    print('For {} handwritten digit we have correct prediction from model. Gratz.'.format(num))\n",
    "else:\n",
    "    print('Looks like model made mistake on {} handwritten digit. Mistakes happens, accuracy is not 100%.'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f9f5d9cf-9571-4223-b18a-bcdf5aa0abe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double-check\n",
    "preds_val[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "431c61b7-2225-431f-91e6-d96fc4107941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double-check\n",
    "y_test[num]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
